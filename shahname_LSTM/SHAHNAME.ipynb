{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SHAHNAME.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"utrZGMnF7deh","colab_type":"code","outputId":"5e3fa9a7-8a3f-4029-a119-4e2df72fc5bb","executionInfo":{"status":"ok","timestamp":1560704690598,"user_tz":-270,"elapsed":1955,"user":{"displayName":"Maryam Meghdadi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDYZFYoOHq4nUb1TsqPOrS_QeWo3iC1Xf8V49ha3w=s64","userId":"09966209550150484662"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import keras\n","keras.__version__\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["'2.2.4'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"-HbUEWwNZ_Qr","colab_type":"code","outputId":"7c915c40-9b02-47cf-fe99-31ecdc40ba9b","executionInfo":{"status":"ok","timestamp":1560704694054,"user_tz":-270,"elapsed":5178,"user":{"displayName":"Maryam Meghdadi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDYZFYoOHq4nUb1TsqPOrS_QeWo3iC1Xf8V49ha3w=s64","userId":"09966209550150484662"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["!nvidia-smi"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Sun Jun 16 17:04:51 2019       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   49C    P8    15W /  70W |      0MiB / 15079MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OzwM9SLr7sZr","colab_type":"code","outputId":"0b1635dd-01aa-4a28-d06a-3fbe6d49a931","executionInfo":{"status":"ok","timestamp":1560704694057,"user_tz":-270,"elapsed":4998,"user":{"displayName":"Maryam Meghdadi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDYZFYoOHq4nUb1TsqPOrS_QeWo3iC1Xf8V49ha3w=s64","userId":"09966209550150484662"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8JidCMC2sGcP","colab_type":"code","colab":{}},"source":["import os\n","os.chdir('drive/My Drive/Colab Notebooks/text generation/final_project1/shahname_LSTM')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aqYNfxEy7dex","colab_type":"text"},"source":["# Text generation with LSTM\n","\n","## Implementing character-level LSTM text generation\n"]},{"cell_type":"code","metadata":{"id":"N64lkTsK7de3","colab_type":"code","outputId":"bfc61427-253e-4beb-e6f5-765e4c9f4fd4","executionInfo":{"status":"ok","timestamp":1560704694062,"user_tz":-270,"elapsed":3533,"user":{"displayName":"Maryam Meghdadi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDYZFYoOHq4nUb1TsqPOrS_QeWo3iC1Xf8V49ha3w=s64","userId":"09966209550150484662"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import keras\n","import numpy as np\n","\n","# path = keras.utils.get_file(\n","#     'nietzsche.txt',\n","#     origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n","path = 'ferdousi_norm.txt'\n","text = open(path).read().lower()\n","print('Corpus length:', len(text))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Corpus length: 2552801\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uFpR486S7dfB","colab_type":"code","outputId":"15125c13-0d3c-46e5-ee36-5b16f783a798","executionInfo":{"status":"ok","timestamp":1560704714313,"user_tz":-270,"elapsed":20324,"user":{"displayName":"Maryam Meghdadi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDYZFYoOHq4nUb1TsqPOrS_QeWo3iC1Xf8V49ha3w=s64","userId":"09966209550150484662"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# Length of extracted character sequences\n","maxlen = 60\n","\n","# We sample a new sequence every `step` characters\n","step = 3\n","\n","# This holds our extracted sequences\n","sentences = []\n","\n","# This holds the targets (the follow-up characters)\n","next_chars = []\n","\n","for i in range(0, len(text) - maxlen, step):\n","    sentences.append(text[i: i + maxlen])\n","    next_chars.append(text[i + maxlen])\n","print('Number of sequences:', len(sentences))\n","\n","# List of unique characters in the corpus\n","chars = sorted(list(set(text)))\n","print('Unique characters:', len(chars))\n","# Dictionary mapping unique characters to their index in `chars`\n","char_indices = dict((char, chars.index(char)) for char in chars)\n","\n","# Next, one-hot encode the characters into binary arrays.\n","print('Vectorization...')\n","x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n","y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n","for i, sentence in enumerate(sentences):\n","    for t, char in enumerate(sentence):\n","        x[i, t, char_indices[char]] = 1\n","    y[i, char_indices[next_chars[i]]] = 1"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Number of sequences: 850914\n","Unique characters: 36\n","Vectorization...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7ByhlG9n7dfL","colab_type":"text"},"source":["## Building the network"]},{"cell_type":"code","metadata":{"id":"OYvKuuH5ceOM","colab_type":"code","colab":{}},"source":["import numpy\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import LSTM\n","from keras.callbacks import ModelCheckpoint\n","from keras.utils import np_utils"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5RQmVahS7dfN","colab_type":"code","colab":{}},"source":["# define the LSTM model\n","model = Sequential()\n","model.add(LSTM(256, input_shape=(maxlen, len(chars)), return_sequences=True))\n","model.add(Dropout(0.2))\n","model.add(LSTM(256))\n","model.add(Dropout(0.2))\n","model.add(Dense(y.shape[1], activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"swch1rId7dfc","colab_type":"text"},"source":["## Training the language model and sampling from it\n","\n","\n","Given a trained model and a seed text snippet, we generate new text by repeatedly:\n","\n","* 1) Drawing from the model a probability distribution over the next character given the text available so far\n","* 2) Reweighting the distribution to a certain \"temperature\"\n","* 3) Sampling the next character at random according to the reweighted distribution\n","* 4) Adding the new character at the end of the available text\n","\n","This is the code we use to reweight the original probability distribution coming out of the model, \n","and draw a character index from it (the \"sampling function\"):"]},{"cell_type":"code","metadata":{"id":"UbW6d_oZ7dfe","colab_type":"code","colab":{}},"source":["def sample(preds, temperature=1.0):\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds) / temperature\n","    exp_preds = np.exp(preds)\n","    preds = exp_preds / np.sum(exp_preds)\n","    probas = np.random.multinomial(1, preds, 1)\n","    return np.argmax(probas)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RaJY7hRwlNZG","colab_type":"code","colab":{}},"source":["# define the checkpoint\n","filepath=\"shah-weights-improvement-{loss:.4f}.hdf5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n","callbacks_list = [checkpoint]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_0lit_gn7dfm","colab_type":"code","colab":{}},"source":["import random\n","import sys\n","from keras.callbacks import ModelCheckpoint\n","\n","\n","for epoch in range(1, 20):\n","    print('epoch', epoch)\n","    # Fit the model for 1 epoch on the available training data\n","    model.fit(x, y,\n","              batch_size=128,\n","              epochs=1,\n","              callbacks=callbacks_list)\n","\n","    # Select a text seed at random\n","    start_index = random.randint(0, len(text) - maxlen - 1)\n","    generated_text = text[start_index: start_index + maxlen]\n","    print('--- Generating with seed: \"' + generated_text + '\"')\n","\n","    for temperature in [0.2, 0.5, 1.0, 1.2]:\n","        print('------ temperature:', temperature)\n","        sys.stdout.write(generated_text)\n","\n","        # We generate 400 characters\n","        for i in range(400):\n","            sampled = np.zeros((1, maxlen, len(chars)))\n","            for t, char in enumerate(generated_text):\n","                sampled[0, t, char_indices[char]] = 1.\n","\n","            preds = model.predict(sampled, verbose=0)[0]\n","            next_index = sample(preds, temperature)\n","            next_char = chars[next_index]\n","\n","            generated_text += next_char\n","            generated_text = generated_text[1:]\n","\n","            sys.stdout.write(next_char)\n","            sys.stdout.flush()\n","        print()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CXmrTIE0kWo-","colab_type":"code","colab":{}},"source":["# load the network weights\n","filename = \"shah-weights13-improvement-1.1059.hdf5\"\n","model.load_weights(filename)\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nTTblTBgko8o","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1428},"outputId":"3ae4b3f7-3e20-48e1-945d-2fc68bfe09f5","executionInfo":{"status":"ok","timestamp":1560704869606,"user_tz":-270,"elapsed":105764,"user":{"displayName":"Maryam Meghdadi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDYZFYoOHq4nUb1TsqPOrS_QeWo3iC1Xf8V49ha3w=s64","userId":"09966209550150484662"}}},"source":["import random\n","import sys\n","# Select a text seed at random\n","start_index = random.randint(0, len(text) - maxlen - 1)\n","generated_text = text[start_index: start_index + maxlen]\n","print('--- Generating with seed: \"' + generated_text + '\"')\n","\n","for temperature in [0.2, 0.5, 1.0, 1.2]:\n","    print('------ temperature:', temperature)\n","    sys.stdout.write(generated_text)\n","\n","    # We generate 400 characters\n","    for i in range(400):\n","        sampled = np.zeros((1, maxlen, len(chars)))\n","        for t, char in enumerate(generated_text):\n","            sampled[0, t, char_indices[char]] = 1.\n","\n","        preds = model.predict(sampled, verbose=0)[0]\n","        next_index = sample(preds, temperature)\n","        next_char = chars[next_index]\n","\n","        generated_text += next_char\n","        generated_text = generated_text[1:]\n","\n","        sys.stdout.write(next_char)\n","        sys.stdout.flush()\n","    print()"],"execution_count":12,"outputs":[{"output_type":"stream","text":["--- Generating with seed: \"ی زیر خاک\n","به دل دوست بهرام چوبینه بود\n","که از شوی جانش پر از ک\"\n","------ temperature: 0.2\n","ی زیر خاک\n","به دل دوست بهرام چوبینه بود\n","که از شوی جانش پر از کین و کین\n","برآمد برو آفرین خواندند\n","برآمد خروشیدن گوسفند\n","به ایران برفتند با او بهم\n","به پیش سپه بود با او بهم\n","بران برز و بالا و ایران سپاه\n","که ای شهریارا نیاید به کار\n","به بالای ایران و تن بر نهاد\n","به بالای ایران به دیدار اوی\n","به نزدیک شاه آمد از شهریار\n","بران گونه بر تخت شاهی نشست\n","به پیش سپه برگرفت از درفش\n","به ایران برآمد ز درد دلیر\n","به نزدیک او بود با او بهم\n","برآمد ز دریا به آوردگاه\n","بدو گفت کای مهتر با سپاه\n","به\n","------ temperature: 0.5\n","ا او بهم\n","برآمد ز دریا به آوردگاه\n","بدو گفت کای مهتر با سپاه\n","به بالای او را به میدان بدند\n","بدان گونه شد سوی دریا رسید\n","سپه را سوی شاه باشد به کار\n","چو بشنید بهرام بر پیش تو\n","برآورد بالا به بر بر نهاد\n","برو مرد با آنک بر دشت کین\n","برفتند با نامداران و گیو\n","بیامد به نزدیک او هرچ بود\n","به ایران ز تخت و ز هر کشوری\n","درم باد و این گردش روزگار\n","که این بدکنش را بدین کار بود\n","چو بشنید گفتار او را به رنج\n","بدان تا در گنجهای کهن\n","چنین نامور بی گمان کار تو\n","نباشند شادان فرستاده ای\n","بدو گفت \n","------ temperature: 1.0\n","ن\n","چنین نامور بی گمان کار تو\n","نباشند شادان فرستاده ای\n","بدو گفت کای شاه نوذر که شهر\n","از اندازه تا دید بر پتیا نیست\n","بران سان که ترکان نشانی میان\n","کنون سوی من کس نبودی سخن\n","بتوران نداریم چرخ بلند\n","چو خفتان ببالا و پنهان ز بهر\n","بدو گفت کای شاه تیر و کمان\n","شهنشاه کاتوت برشد دوان\n","برو گرد پولاد و نگشود و پیش\n","کجا بست و بارانش بفراختی\n","چو کاوس نیریر گردد نگاه\n","سپهدار پیران پر از درد شد\n","همی رفت با شاه لشکرش نام\n","که اندر جهان ما رهانی بدی\n","که جان تو توران بد این هوشیار\n","بشد دست مر\n","------ temperature: 1.2\n","ر جهان ما رهانی بدی\n","که جان تو توران بد این هوشیار\n","بشد دست مردم سوی ماه کین\n","گزین کرده از صف بخودنک مرد\n","بدو بازگردد به شیداز خزر\n","پزشکان ژیاه سپه را سخن\n","زمشکیب بس دل روشن مخت\n","و زآن جامه کردی همی چندگان\n","فراوان فگندند خورشید و ماه\n","که زین پس نبردم مهان دیو باز\n","ز گردان چرین دادست کیقباد\n","ببازو و بیدار هندی گهر\n","گشاده و را دختری پروریم\n","شد آسان ز تاره فراخ بهشت\n","چو شهری بزرگان و چشم سپاه\n","شما را در گردن آسیاب\n","به فاس اندرون خسته جنگ آورید\n","می و تیغ زدنگشت چندی ز سوی\n","همان\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6gng1ZahXlAh","colab_type":"text"},"source":["A low temperature results in extremely repetitive and predictable text, but where local structure is highly realistic: in \n","particular, all words (a word being a local pattern of characters) are real words. With higher temperatures, the generated text \n","becomes more interesting, surprising, even creative; it may sometimes invent completely new words that sound somewhat plausible. With a high temperature, the local structure starts breaking down and most words look like semi-random strings \n","of characters. Without a doubt, here **0.5 is the most interesting temperature for text generation in this specific setup.** Always experiment \n","with multiple sampling strategies! A clever balance between learned structure and randomness is what makes generation interesting.\n"]},{"cell_type":"code","metadata":{"id":"0GLnjLo7QHK5","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}